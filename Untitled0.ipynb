{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1kYXO5fUw3LbaObRb45ihe1T1yq5JuhDp",
      "authorship_tag": "ABX9TyM56tTZpRM/wUOaaTS8NWHB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patycka/ImageDetectionHelicopterPassengerPlane/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nUZygV5loki"
      },
      "source": [
        "# Update: Należy użyć biblioteki tensorflow w wersji 2.0\n",
        "#!pip install gast==0.2.2\n",
        "!pip install -q tensorflow==2.0"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyT4WDh6svj5"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PtHttm-i6tr"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "#copy files\n",
        "import shutil\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "#augmentation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "np.set_printoptions(precision=6, suppress=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdupLNcSsYYO"
      },
      "source": [
        "# Get data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sguT12FNsuQg",
        "outputId": "ef8c7ed1-c33d-4e50-b720-f4fdb2cfc45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/esmartdata-courses-files/ann-course/flying-vehicles.zip\n",
        "!unzip -q flying-vehicles.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-18 11:31:44--  https://storage.googleapis.com/esmartdata-courses-files/ann-course/flying-vehicles.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 74.125.197.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1540232238 (1.4G) [application/x-zip-compressed]\n",
            "Saving to: ‘flying-vehicles.zip.1’\n",
            "\n",
            "flying-vehicles.zip 100%[===================>]   1.43G   102MB/s    in 20s     \n",
            "\n",
            "2020-10-18 11:32:05 (74.8 MB/s) - ‘flying-vehicles.zip.1’ saved [1540232238/1540232238]\n",
            "\n",
            "replace data/planes/drone/00000000.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QzNt6aHq2Ue"
      },
      "source": [
        "# Przygotowanie zbiorów: treningowego, walidacyjnego i testowego"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czl70tKboVWd"
      },
      "source": [
        "!rm -rf ./images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyEslaTCubUU"
      },
      "source": [
        "base_dir = './data/planes'\n",
        "raw_no_of_files = {}\n",
        "classes = ['drone', 'fighter-jet', 'helicopter', 'missile', 'passenger-plane', 'rocket']\n",
        "for dir in classes:\n",
        "    raw_no_of_files[dir] = len(os.listdir(os.path.join(base_dir, dir)))\n",
        "\n",
        "raw_no_of_files.items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDPxmg03wlSo"
      },
      "source": [
        "data_dir = './images'\n",
        "\n",
        "if not os.path.exists(data_dir):\n",
        "  os.mkdir(data_dir)\n",
        "\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "valid_dir = os.path.join(data_dir, 'valid')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "train_helicopter_dir = os.path.join(train_dir, 'helicopter')\n",
        "valid_helicopter_dir = os.path.join(valid_dir, 'helicopter')\n",
        "test_helicopter_dir = os.path.join(test_dir, 'helicopter')\n",
        "\n",
        "train_passenger_plane_dir = os.path.join(train_dir, 'passenger_plane')\n",
        "valid_passenger_plane_dir = os.path.join(valid_dir, 'passenger_plane')\n",
        "test_passenger_plane_dir = os.path.join(test_dir, 'passenger_plane')\n",
        "\n",
        "dirs = [train_helicopter_dir, valid_helicopter_dir, test_helicopter_dir,\n",
        "        train_passenger_plane_dir, valid_passenger_plane_dir, test_passenger_plane_dir]\n",
        "\n",
        "for directory in (train_dir, valid_dir, test_dir):\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "for directory in dirs:\n",
        "  if not os.path.exists(directory):\n",
        "    os.mkdir(directory)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ANHpuVC_LVN"
      },
      "source": [
        "# list all files from directory helicopter and passenger-plane\n",
        "helicopter_fnames = os.listdir(os.path.join(base_dir, 'helicopter'))\n",
        "passenger_plane_fnames = os.listdir(os.path.join(base_dir, 'passenger-plane'))\n",
        "\n",
        "# choose only files with extension .jpg, .png and .jpeg\n",
        "# iterating through the list using list comprehension\n",
        "helicopter_fnames = [fname for fname in helicopter_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
        "passenger_plane_fnames = [fname for fname in passenger_plane_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
        "\n",
        "size = min(len(helicopter_fnames), len(passenger_plane_fnames))\n",
        "print(\"Common min amount of photos\")\n",
        "print(size)\n",
        "\n",
        "# func floor cuts off the fraction\n",
        "train_size = np.floor(0.7*size)\n",
        "valid_size = np.floor(0.2*size)\n",
        "test_size = size - train_size - valid_size\n",
        "\n",
        "train_end_idx = train_size\n",
        "valid_end_idx = train_end_idx + valid_size\n",
        "test_end_idx = valid_end_idx + test_size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNhRiyMX2FrO"
      },
      "source": [
        "# copy files from data to test, train and validation folders\n",
        "helicopter_original_dir = os.path.join(base_dir, 'helicopter')\n",
        "passenger_plane_original_dir = os.path.join(base_dir, 'passenger-plane')\n",
        "\n",
        "i=0\n",
        "for i, fname in enumerate(helicopter_fnames):\n",
        "  if i < train_end_idx:\n",
        "    shutil.copyfile(os.path.join(helicopter_original_dir, fname),\n",
        "                    os.path.join(train_helicopter_dir, fname))\n",
        "  elif i < valid_end_idx:\n",
        "    shutil.copyfile(os.path.join(helicopter_original_dir, fname), \n",
        "                    os.path.join(valid_helicopter_dir, fname))\n",
        "  else:\n",
        "    shutil.copyfile(os.path.join(helicopter_original_dir, fname), \n",
        "                    os.path.join(test_helicopter_dir, fname))\n",
        "    i = i+1\n",
        "\n",
        "i=0\n",
        "for i, fname in enumerate(passenger_plane_fnames):\n",
        "  if i < train_end_idx:\n",
        "    shutil.copyfile(os.path.join(passenger_plane_original_dir, fname), \n",
        "                    os.path.join(train_passenger_plane_dir, fname))\n",
        "  elif i < valid_end_idx:\n",
        "    shutil.copyfile(os.path.join(passenger_plane_original_dir, fname), \n",
        "                    os.path.join(valid_passenger_plane_dir, fname))\n",
        "  else:\n",
        "    shutil.copyfile(os.path.join(passenger_plane_original_dir, fname), \n",
        "                    os.path.join(test_passenger_plane_dir, fname))\n",
        "    i = i+1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfIdDNq1hWEw"
      },
      "source": [
        "# print how many images is in train, test and validation folders\n",
        "print('Number of training helicopter images: ', len(os.listdir(train_helicopter_dir)))\n",
        "print('Number of validation helicopter images: ', len(os.listdir(valid_helicopter_dir)))\n",
        "print('Number of test helicopter images: ', len(os.listdir(test_helicopter_dir)))\n",
        "\n",
        "print('Number of training passenger-plane images: ', len(os.listdir(train_helicopter_dir)))\n",
        "print('Number of validation passenger-plane images: ', len(os.listdir(valid_helicopter_dir)))\n",
        "print('Number of test passenger-plane images: ', len(os.listdir(test_helicopter_dir)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXaDOd6Tpz22"
      },
      "source": [
        "Present data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEWd8omemeK2"
      },
      "source": [
        "#@title Choose index of helicopter image\n",
        "idx = 97 #@param {type: 'slider', min:0, max:1000}\n",
        "names_maping = dict(enumerate(helicopter_fnames))\n",
        "img_path = os.path.join(train_helicopter_dir, names_maping[idx])\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.grid(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXffK9l2qQb_"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQzVRGzsqUl0"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=40,      \n",
        "    rescale= 1./255.,\n",
        "    width_shift_range=0.2,  #pionowe przeksztalcenia obrazu\n",
        "    height_shift_range=0.2, #poziome przeksztalcenia obrazu\n",
        "    shear_range=0.2,        #zakres losowego przycinania obrazu\n",
        "    zoom_range=0.2,         #zakres losowego przyblizania obrazu\n",
        "    horizontal_flip=True,   #losowe odbicie polowy obrazu w plaszczyznie poziomej\n",
        "    fill_mode='nearest'     #strategia wypelniania nowo stworzonych pikseli, ktore moga powstac w wyniku przeksztalcen\n",
        ")\n",
        "\n",
        "#przeskalowanie obrazow o wspolczynnik 1/255\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(directory=train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(directory=valid_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U1geXve21Ga"
      },
      "source": [
        "# Model build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnataavF25Q8"
      },
      "source": [
        "# build model relies of adding layers\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(units=512, activation='relu'))\n",
        "model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h52lWHG7E6N"
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsNKA7vp7z_P"
      },
      "source": [
        "!rm -rf logs\n",
        "!mkdir logs\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eprZMN9P8ExL",
        "outputId": "3676876b-8abf-400a-ac2e-de9bdfe7de3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "batch_size=32\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = valid_size // batch_size\n",
        "\n",
        "print(steps_per_epoch)\n",
        "print(validation_steps)\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                              steps_per_epoch=steps_per_epoch,\n",
        "                              epochs=30,\n",
        "                              validation_data=valid_generator,\n",
        "                              validation_steps=validation_steps,\n",
        "                              callbacks=[tensorboard])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d92ccee73196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdkPyU0BLv1f"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1JLgVr9ML5k"
      },
      "source": [
        "!tensorboard dev upload --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01UCw6uZrBGD"
      },
      "source": [
        "# Evaluation of the model on a test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Aquxg3rsAw-"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=1,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "y_prob = model.predict_generator(test_generator, test_generator.samples)\n",
        "y_prob = y_prob.ravel()\n",
        "y_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67FERGTetJ7D"
      },
      "source": [
        "predictions  = pd.DataFrame({'y_prob': y_prob})\n",
        "predictions['class'] = predictions['y_prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFePvwzctaBR"
      },
      "source": [
        "y_true = test_generator.classes\n",
        "y_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BprrCavetd2R"
      },
      "source": [
        "y_pred = predictions['class'].values\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIymcPOrtj7T"
      },
      "source": [
        "test_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41H-3dyDtoT2"
      },
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLyX4AucttuE"
      },
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh00Q_q3uBPP"
      },
      "source": [
        "# Display of prediction errors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXjQrck4uHG_"
      },
      "source": [
        "errors = pd.DataFrame({'y_true': y_true, 'y_pred': y_pred}, index=test_generator.filenames)\n",
        "errors.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_TLF2hGuTnB"
      },
      "source": [
        "errors['is_incorrect'] = (errors['y_true'] != errors['y_pred']) * 1\n",
        "errors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOu5JppouYvI"
      },
      "source": [
        "errors[errors['is_incorrect'] == 1].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImAIT-vZufgo"
      },
      "source": [
        "img_path = os.path.join(test_helicopter_dir, '00000427.jpg')\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2kk7Skqu5od"
      },
      "source": [
        "errors[errors['is_incorrect'] == 1].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIJRlQnDu_WZ"
      },
      "source": [
        "img_path = os.path.join(test_passenger_plane_dir, '00000224.jpg')\n",
        "\n",
        "img = image.load_img(img_path)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(img)\n",
        "plt.grid(False)\n",
        "plt.axis(False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}